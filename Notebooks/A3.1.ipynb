{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9pWsPAt0dCh"
   },
   "source": [
    "# Assignment 3 Part 1 - Python for Text Processing\n",
    "\n",
    "*Submission deadline: Friday 3 May 2024, 11:55pm.*\n",
    "\n",
    "*Assessment marks: 10 marks (10% of the total unit assessment)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unless a Special Consideration request has been submitted and approved, a 5% penalty (of the total possible mark of the task) will be applied for each day a written report or presentation assessment is not submitted, up until the 7th day (including weekends). After the 7th day, a grade of ‘0’ will be awarded even if the assessment is submitted. The submission time for all uploaded assessments is 11:55 pm. A 1-hour grace period will be provided to students who experience a technical concern. For any late submission of time-sensitive tasks, such as scheduled tests/exams, performance assessments/presentations, and/or scheduled practical assessments/labs, please apply for [Special Consideration](https://students.mq.edu.au/study/assessment-exams/special-consideration).\n",
    "\n",
    "Note that the work submitted should be your own work. You are allowed to use AI-based code generators to help you understand the problem and possible solutions, but you are not allowed to use the code generated by these tools (see below).\n",
    "\n",
    "You are allowed to base your code on the code presented in the unit lectures and lecture notebooks.\n",
    "\n",
    "**A note on the use of AI generators**: In this assignment, we view AI code generators such as copilot, CodeGPT, etc as tools that can help you write code quickly. You are allowed to use these tools, but with some conditions. To understand what you can and what you cannot do, please visit these information pages provided by Macquarie University.\n",
    "\n",
    "Artificial Intelligence Tools and Academic Integrity in FSE - https://bit.ly/3uxgQP4\n",
    "If you choose to use these tools, make the following explicit in your Jupyter notebook, under a section with heading \"Use of AI generators in this assignment\" :\n",
    "\n",
    "* What part of your code is based on the output of such tools,\n",
    "* What tools you used,\n",
    "* What prompts you used to generate the code or text, and\n",
    "* What modifications you made on the generated code or text.\n",
    "  \n",
    "This will help us assess your work fairly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives of this assignment\n",
    "\n",
    "In assignment 3 you will work on a task of \"query-focused summarisation\" on medical questions where the goal is, given a medical question and a list of sentences extracted from relevant medical publications, to determine which of these sentences from the list can be used as part of the answer to the question. Assignment 3 is divided into two parts. Part 1 will help you get familar with the data, and Part 2 requires you to implement deep neural networks.\n",
    "\n",
    "We will use data that has been derived from the **BioASQ challenge** (http://www.bioasq.org/), after some data manipulation to make it easier to process for this assignment. The BioASQ challenge organises several \"shared tasks\", including a task on biomedical semantic question answering which we are using here. The data are in the file `bioasq10_labelled.csv`, which is part of the zip file provided. Each row of the file has a question, a sentence text, and a label that indicates whether the sentence text is part of the answer to the question (1) or not (0).\n",
    "\n",
    "The following code uses pandas to store the file `bioasq10_labelled.csv` in a data frame and show the first rows of data. For this code to run, first you need to unzip the file `data.zip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  data.zip\n",
      "  inflating: bioasq10b_labelled.csv  \n",
      "  inflating: dev_test.csv            \n",
      "  inflating: test.csv                \n",
      "  inflating: training.csv            \n"
     ]
    }
   ],
   "source": [
    "!unzip data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>sentid</th>\n",
       "      <th>question</th>\n",
       "      <th>sentence text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>Hirschsprung disease (HSCR) is a multifactoria...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>In this study, we review the identification of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>The majority of the identified genes are relat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>The non-Mendelian inheritance of sporadic non-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Is Hirschsprung disease a mendelian or a multi...</td>\n",
       "      <td>Coding sequence mutations in e.g.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   qid  sentid                                           question  \\\n",
       "0    0       0  Is Hirschsprung disease a mendelian or a multi...   \n",
       "1    0       1  Is Hirschsprung disease a mendelian or a multi...   \n",
       "2    0       2  Is Hirschsprung disease a mendelian or a multi...   \n",
       "3    0       3  Is Hirschsprung disease a mendelian or a multi...   \n",
       "4    0       4  Is Hirschsprung disease a mendelian or a multi...   \n",
       "\n",
       "                                       sentence text  label  \n",
       "0  Hirschsprung disease (HSCR) is a multifactoria...      0  \n",
       "1  In this study, we review the identification of...      1  \n",
       "2  The majority of the identified genes are relat...      1  \n",
       "3  The non-Mendelian inheritance of sporadic non-...      1  \n",
       "4                  Coding sequence mutations in e.g.      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"bioasq10b_labelled.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of the CSV file are:\n",
    "\n",
    "* `qid`: an ID for a question. Several rows may have the same question ID, as we can see above.\n",
    "* `sentid`: an ID for a sentence.\n",
    "* `question`: The text of the question. In the above example, the first rows all have the same question: \"Is Hirschsprung disease a mendelian or a multifactorial disorder?\"\n",
    "* `sentence text`: The text of the sentence.\n",
    "* `label`: 1 if the sentence is a part of the answer, 0 if the sentence is not part of the answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You are provided with a template that contains the definitions of the functions that you need to implement in each of the tasks below. The template includes sample [Python doctests](https://docs.python.org/3/library/doctest.html) that you can use to check the correctness of the code. These tests are there to help you. But note that we will use a separate set of tests when we assess your submission. It is your responsibility to run your own tests, in addition to the doctests provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Tasks\n",
    "\n",
    "### 1. Statistics of part of speech (3 marks)\n",
    "\n",
    "Implement a function `stats_pos` that returns the normalized frequency of all appeared part of speech in the questions and answers (namely the `sentence text` column), respectively. To find the part of speech, use NLTK's \"Universal\" tag set. You may need to use NLTK's sent_tokenize and word_tokenize to get words. Each of the resulting two lists (one for questions, one for answers) must be sorted alphabetically according to tags, e.g. [(ADV,0.1), (NOUN,0.21),...].\n",
    "\n",
    "The input argument of the function is a csv file path.\n",
    "\n",
    "To produce the correct results, the function must do this:\n",
    "* Just keep unique questions\n",
    "* Concatenate all questions together. Same to the answers.\n",
    "* Use the NLTK libraries to find the tokens and the stems. \n",
    "* Use NLTK's sentence tokeniser before NLTK's word tokeniser.\n",
    "* Use NLTK's part of speech tagger, using the \"Universal\" tagset.\n",
    "* Use NLTK's `pos_tag_sents` instead of `pos_tag`.\n",
    "* Using a few of sentences to analyse whether the PoS of questions has similar distributions with answers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('.', 0.1201),\n",
       "  ('ADJ', 0.0892),\n",
       "  ('ADP', 0.1119),\n",
       "  ('ADV', 0.011),\n",
       "  ('CONJ', 0.0085),\n",
       "  ('DET', 0.085),\n",
       "  ('NOUN', 0.3536),\n",
       "  ('NUM', 0.0056),\n",
       "  ('PRON', 0.0377),\n",
       "  ('PRT', 0.0104),\n",
       "  ('VERB', 0.1659),\n",
       "  ('X', 0.0011)],\n",
       " [('.', 0.123),\n",
       "  ('ADJ', 0.1203),\n",
       "  ('ADP', 0.1173),\n",
       "  ('ADV', 0.0244),\n",
       "  ('CONJ', 0.0349),\n",
       "  ('DET', 0.0771),\n",
       "  ('NOUN', 0.3466),\n",
       "  ('NUM', 0.0186),\n",
       "  ('PRON', 0.0099),\n",
       "  ('PRT', 0.0158),\n",
       "  ('VERB', 0.1115),\n",
       "  ('X', 0.0008)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import a3_1\n",
    "a3_1.stats_pos('dev_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Statistics of the top stem n-grams (3 marks)\n",
    "\n",
    "Implement a function `stats_top_stem_ngrams` that returns the N most frequent n-gram of stems together with their normalized frequency for questions and answers, respectively. You must return two lists (one for questions, and the other one for answers), and each is sorted in descending order of frequency, e.g. if it is 1-gram, then each returned list should look like [(how,0.18),(study,0.06),...].\n",
    "\n",
    "The input arguments are:\n",
    "\n",
    "* csv_file_path\n",
    "* *n*: The parameter of n-gram, which denotes the number of words. Eg, if n=2, then n-grams will be 2-grams\n",
    "* *N*: Top N n-grams.\n",
    "\n",
    "To produce the correct results, the function must do this:\n",
    "\n",
    "* Just keep unique questions\n",
    "* Concatenate all questions together. Same to the answers.\n",
    "* Use the NLTK libraries to find the tokens and the stems. \n",
    "* Use NLTK's sentence tokeniser before NLTK's word tokeniser.\n",
    "* Use NLTK's Porter stemmer to get the root words.\n",
    "* When computing bigrams, do not consider words that are in different sentences. For example, if we have this text: \"Sentence 1. And sentence 2.\" the bigrams are: `('Sentence','1'), ('1','.'), ('And','sentence'), ('sentence','2'), ('2','.')`. Note that the following would not be a valid bigram, since the punctuation mark and the word \"And\" are in different sentences: `('.','And')`.\n",
    "* Set n=2 and N=5, then use a few of sentences to describe the overlap between questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(('what', 'is'), 0.0294),\n",
       "  (('is', 'the'), 0.0265),\n",
       "  (('of', 'the'), 0.0104),\n",
       "  (('in', 'the'), 0.006),\n",
       "  (('are', 'the'), 0.0055)],\n",
       " [(('of', 'the'), 0.0065),\n",
       "  (('in', 'the'), 0.0055),\n",
       "  ((',', 'and'), 0.0053),\n",
       "  ((')', ','), 0.004),\n",
       "  (('is', 'a'), 0.003)])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import a3_1\n",
    "a3_1.stats_top_stem_ngrams('dev_test.csv',2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Statistics of Named Entity (2 marks)\n",
    "Implement a function `stats_ne` that returns the normalized frequency of all named entity types for questions and answers, respectively. Using the default entity types of spacy. The resulting two lists have the same format as in Task 1.\n",
    "\n",
    "The result will vary when using different Named Entity Recognition Models. To be consistent, you are required to use `en_core_web_sm` with the spaCy tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('CARDINAL', 0.0966),\n",
       "  ('DATE', 0.0207),\n",
       "  ('EVENT', 0.0046),\n",
       "  ('FAC', 0.0046),\n",
       "  ('GPE', 0.1172),\n",
       "  ('LAW', 0.0092),\n",
       "  ('LOC', 0.0138),\n",
       "  ('NORP', 0.0529),\n",
       "  ('ORDINAL', 0.0115),\n",
       "  ('ORG', 0.3977),\n",
       "  ('PERCENT', 0.0023),\n",
       "  ('PERSON', 0.2115),\n",
       "  ('PRODUCT', 0.0483),\n",
       "  ('QUANTITY', 0.0023),\n",
       "  ('WORK_OF_ART', 0.0069)],\n",
       " [('CARDINAL', 0.2141),\n",
       "  ('DATE', 0.0528),\n",
       "  ('EVENT', 0.001),\n",
       "  ('FAC', 0.0037),\n",
       "  ('GPE', 0.0717),\n",
       "  ('LANGUAGE', 0.0001),\n",
       "  ('LAW', 0.0044),\n",
       "  ('LOC', 0.0078),\n",
       "  ('MONEY', 0.0021),\n",
       "  ('NORP', 0.0348),\n",
       "  ('ORDINAL', 0.0202),\n",
       "  ('ORG', 0.3784),\n",
       "  ('PERCENT', 0.0303),\n",
       "  ('PERSON', 0.1364),\n",
       "  ('PRODUCT', 0.0288),\n",
       "  ('QUANTITY', 0.0065),\n",
       "  ('TIME', 0.0025),\n",
       "  ('WORK_OF_ART', 0.0044)])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import a3_1\n",
    "a3_1.stats_ne('dev_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Statistics of tf.idf-based similarity (2 marks)\n",
    "\n",
    "Implement a function `stats_tfidf` that returns the ratio of questions that its most similar sentence falls in its answers. That means you need to calculate the cosine similarity between one question and all sentences in the `sentence text` column, and check whether the sentence with the highest similarity falls in the answers of the question. To compute the tf.idf, use sklearn's TfidfVectorizer with the option to remove the English stop words (stop_words='english'). \n",
    "\n",
    "To produce correct results, the function must do this:\n",
    "\n",
    "* Use Scikit-learn's `TfidfVectorizer` with the option `stop_words='english'`.\n",
    "* Fit the tfidf vectorizer using all unique questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4876"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import a3_1\n",
    "a3_1.stats_tfidf('dev_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "The submission must be a single Python file. Do not submit several files or a zip file since the automarker would not know what to do with your submission. Do not submit a Jupyter notebook."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "A2_solution.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "a7b63e7410c98f344f02082f10d790581d1dba1eeb1c8fe30f342f6109f0429e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
